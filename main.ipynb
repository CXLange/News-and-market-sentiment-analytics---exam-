{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "true_data = pd.read_csv('data/True.csv')\n",
    "fake_data = pd.read_csv('data/Fake.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a single, clean dataset with labels for true = 1 and false = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 6 duplicate title rows from true articles\n",
      "Removed 184 duplicate title rows from fake articles\n",
      "\n",
      "Removed 229 duplicate text rows from true articles\n",
      "Removed 5398 duplicate text rows from fake articles\n",
      "______________________________________________________________________\n",
      "Removed 235 duplicate rows from true articles in total\n",
      "Removed 5582 duplicate rows from fake articles in total\n"
     ]
    }
   ],
   "source": [
    "# Creating a single dataset with labels for true = 1 and false = 0\n",
    "\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# Cleaning true_data before concatinating\n",
    "## Removing journal identifier\n",
    "true_data['text'] = true_data['text'].str.partition('- ')[2]\n",
    "\n",
    "# Removing duplicates rows of titles where text is empty\n",
    "# Create a boolean placeholder to check if text is empty\n",
    "is_text_functionally_empty = (\n",
    "    true_data['text'].isna() | \n",
    "    true_data['text'].astype(str).str.strip().eq('')\n",
    ")\n",
    "# Drop rows if true and keep first instance of title if there are duplicates\n",
    "rows_to_drop = true_data[is_text_functionally_empty].duplicated(subset=['title'], keep='first')\n",
    "drop_indices = true_data[is_text_functionally_empty][rows_to_drop].index\n",
    "cleaned_true = true_data.drop(index=drop_indices)\n",
    "# Doing the same for fake articles\n",
    "fake_is_text_functionally_empty = (\n",
    "    fake_data['text'].isna() | \n",
    "    fake_data['text'].astype(str).str.strip().eq('')\n",
    ")\n",
    "rows_to_drop = fake_data[fake_is_text_functionally_empty].duplicated(subset=['title'], keep='first')\n",
    "drop_indices = fake_data[fake_is_text_functionally_empty][rows_to_drop].index\n",
    "cleaned_fake = fake_data.drop(index=drop_indices)\n",
    "\n",
    "print(f\"Removed {len(true_data)-len(cleaned_true)} duplicate title rows from true articles\")\n",
    "print(f\"Removed {len(fake_data)-len(cleaned_fake)} duplicate title rows from fake articles\")\n",
    "print(\"\")\n",
    "\n",
    "# Removing duplicates of text but keeping unique rows of title\n",
    "has_content = ~(\n",
    "    cleaned_fake['text'].isna() |\n",
    "    cleaned_fake['text'].astype(str).str.strip().eq('')\n",
    ")\n",
    "rows_to_remove = cleaned_fake[has_content].duplicated(subset=['text'], keep='first')\n",
    "\n",
    "drop_indices = cleaned_fake[has_content][rows_to_remove].index\n",
    "\n",
    "new_cleaned_fake = cleaned_fake.drop(index=drop_indices)\n",
    "\n",
    "# Doing the same for true articles\n",
    "\n",
    "has_content = ~(\n",
    "    cleaned_true['text'].isna() |\n",
    "    cleaned_true['text'].astype(str).str.strip().eq('')\n",
    ")\n",
    "rows_to_remove = cleaned_true[has_content].duplicated(subset=['text'], keep='first')\n",
    "\n",
    "drop_indices = cleaned_true[has_content][rows_to_remove].index\n",
    "\n",
    "new_cleaned_true = cleaned_true.drop(index=drop_indices)\n",
    "\n",
    "print(f\"Removed {len(cleaned_true)-len(new_cleaned_true)} duplicate text rows from true articles\")\n",
    "print(f\"Removed {len(cleaned_fake)-len(new_cleaned_fake)} duplicate text rows from fake articles\")\n",
    "print(\"______________________________________________________________________\")\n",
    "print(f\"Removed {len(true_data)-len(new_cleaned_true)} duplicate rows from true articles in total\")\n",
    "print(f\"Removed {len(fake_data)-len(new_cleaned_fake)} duplicate rows from fake articles in total\")\n",
    "\n",
    "# Concatinating dataframes\n",
    "data = pd.concat([new_cleaned_true, new_cleaned_fake])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text standardizing\n",
    "# pip install string\n",
    "import string\n",
    "\n",
    "# Creating new columns to preserve original text\n",
    "data['title_standard'] = data['title']\n",
    "data['text_standard'] = data['text']\n",
    "\n",
    "# Removing punctuations including special letter which didn't get picked up by string.punctuation\n",
    "punctuation_and_special = string.punctuation + '“”‘’' \n",
    "punctuation = str.maketrans('', '', punctuation_and_special)\n",
    "\n",
    "data['title_standard'] = data['title'].astype(str).str.translate(punctuation)\n",
    "data['text_standard'] = data['text'].astype(str).str.translate(punctuation)\n",
    "\n",
    "# Lowercasing \n",
    "data['title_standard'] = data['title_standard'].astype(str).str.strip().str.lower()\n",
    "data['text_standard'] = data['text_standard'].astype(str).str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aiming for a baseline with naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes Classification Results (Using Raw Word Counts) ---\n",
      "Accuracy: 0.9424\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      3580\n",
      "           1       0.93      0.97      0.95      4237\n",
      "\n",
      "    accuracy                           0.94      7817\n",
      "   macro avg       0.94      0.94      0.94      7817\n",
      "weighted avg       0.94      0.94      0.94      7817\n",
      "\n",
      "--- Top 20 Words Predicting FAKE News (Label 0) ---\n",
      "| feature             |   fake_score |\n",
      "|:--------------------|-------------:|\n",
      "| 2017realdonaldtrump |      7.0647  |\n",
      "| 21wire              |      6.35848 |\n",
      "| belowfeatured       |      6.28281 |\n",
      "| getty               |      6.2585  |\n",
      "| 2017the             |      6.08819 |\n",
      "| flickr              |      6.06944 |\n",
      "| 21wiretv            |      5.91799 |\n",
      "| 2016realdonaldtrump |      5.82926 |\n",
      "| somodevillagetty    |      5.74693 |\n",
      "| screenshot          |      5.74319 |\n",
      "| acr                 |      5.70112 |\n",
      "| cdata               |      5.68933 |\n",
      "| js                  |      5.66127 |\n",
      "| filessupport        |      5.63658 |\n",
      "| 2017trump           |      5.53122 |\n",
      "| wonggetty           |      5.47895 |\n",
      "| 2016the             |      5.45426 |\n",
      "| reilly              |      5.38169 |\n",
      "| finicum             |      5.35995 |\n",
      "| angerergetty        |      5.35444 |\n",
      "\n",
      "--- Top 20 Words Predicting TRUE News (Label 1) ---\n",
      "| feature    |   fake_score |\n",
      "|:-----------|-------------:|\n",
      "| rohingya   |     -7.25682 |\n",
      "| myanmar    |     -6.45431 |\n",
      "| rakhine    |     -6.43847 |\n",
      "| puigdemont |     -6.0706  |\n",
      "| partys     |     -5.9148  |\n",
      "| fdp        |     -5.88906 |\n",
      "| zuma       |     -5.7973  |\n",
      "| suu        |     -5.76295 |\n",
      "| kyi        |     -5.75486 |\n",
      "| hariri     |     -5.66858 |\n",
      "| rajoy      |     -5.61238 |\n",
      "| mnangagwa  |     -5.55449 |\n",
      "| odinga     |     -5.5445  |\n",
      "| anc        |     -5.53103 |\n",
      "| catalan    |     -5.47407 |\n",
      "| chinas     |     -5.42001 |\n",
      "| juncker    |     -5.40474 |\n",
      "| countrys   |     -5.30789 |\n",
      "| barnier    |     -5.30364 |\n",
      "| kuczynski  |     -5.28214 |\n"
     ]
    }
   ],
   "source": [
    "# Baseline naive bayes model for article texts\n",
    "# pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "X = data['text_standard']  \n",
    "y = data['label']\n",
    "\n",
    "# Splitting the data and making sure we get the same number of labels in each set with stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Setting max_df to 0.7 we exclude words that appears in more than 70% of all articles in the training set so we should get more unique words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Train Multinomial Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred_counts = nb_classifier.predict(X_test_counts)\n",
    "\n",
    "# Get the feature names to see which words are helping us predict\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Getting log coefficients \n",
    "log_probs_fake = nb_classifier.feature_log_prob_[0]\n",
    "log_probs_true = nb_classifier.feature_log_prob_[1]\n",
    "\n",
    "# Create a DataFrame so we can sort them \n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'log_prob_fake': log_probs_fake,\n",
    "    'log_prob_true': log_probs_true\n",
    "})\n",
    "\n",
    "# Calculate the difference between coefficients \n",
    "# A larger positive difference means the word is highly associated with fake news\n",
    "feature_df['fake_score'] = feature_df['log_prob_fake'] - feature_df['log_prob_true']\n",
    "\n",
    "# Get top 20 for Fake (highest positive scores)\n",
    "top_fake_features = feature_df.sort_values(by='fake_score', ascending=False).head(20)\n",
    "\n",
    "# Get top 20 for True (lowest negative scores)\n",
    "top_true_features = feature_df.sort_values(by='fake_score', ascending=True).head(20)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"--- Naive Bayes Classification Results (Using Raw Word Counts) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_counts):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_counts))\n",
    "\n",
    "# Print important classifying words\n",
    "print(\"--- Top 20 Words Predicting FAKE News (Label 0) ---\")\n",
    "print(top_fake_features[['feature', 'fake_score']].to_markdown(index=False))\n",
    "\n",
    "print(\"\\n--- Top 20 Words Predicting TRUE News (Label 1) ---\")\n",
    "print(top_true_features[['feature', 'fake_score']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same for article titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes Classification Results (Using Raw Word Counts) ---\n",
      "Accuracy: 0.9364\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3580\n",
      "           1       0.95      0.93      0.94      4237\n",
      "\n",
      "    accuracy                           0.94      7817\n",
      "   macro avg       0.94      0.94      0.94      7817\n",
      "weighted avg       0.94      0.94      0.94      7817\n",
      "\n",
      "--- Top 20 Words Predicting FAKE News (Label 0) ---\n",
      "| feature     |   fake_score |\n",
      "|:------------|-------------:|\n",
      "| hillarys    |      5.25011 |\n",
      "| wow         |      5.09675 |\n",
      "| video       |      5.09181 |\n",
      "| heres       |      5.09121 |\n",
      "| hilarious   |      4.89547 |\n",
      "| busted      |      4.62564 |\n",
      "| bombshell   |      4.51338 |\n",
      "| hilariously |      4.49337 |\n",
      "| epic        |      4.47297 |\n",
      "| sarah       |      4.45213 |\n",
      "| gop         |      4.44685 |\n",
      "| supporter   |      4.43085 |\n",
      "| fck         |      4.32907 |\n",
      "| brilliant   |      4.32907 |\n",
      "| awesome     |      4.30497 |\n",
      "| dem         |      4.30497 |\n",
      "| lol         |      4.30497 |\n",
      "| disgusting  |      4.24206 |\n",
      "| racist      |      4.24206 |\n",
      "| boiler      |      4.21574 |\n",
      "\n",
      "--- Top 20 Words Predicting TRUE News (Label 1) ---\n",
      "| feature    |   fake_score |\n",
      "|:-----------|-------------:|\n",
      "| factbox    |     -5.88249 |\n",
      "| myanmar    |     -5.38495 |\n",
      "| catalan    |     -5.17065 |\n",
      "| rohingya   |     -5.13218 |\n",
      "| kurdish    |     -4.77457 |\n",
      "| envoy      |     -4.73647 |\n",
      "| xi         |     -4.6126  |\n",
      "| referendum |     -4.47119 |\n",
      "| catalonia  |     -4.45845 |\n",
      "| ria        |     -4.40581 |\n",
      "| zimbabwe   |     -4.36443 |\n",
      "| hariri     |     -4.27613 |\n",
      "| zimbabwes  |     -4.22888 |\n",
      "| asia       |     -4.22888 |\n",
      "| bangladesh |     -4.21262 |\n",
      "| ireland    |     -4.21262 |\n",
      "| kurds      |     -4.16219 |\n",
      "| chinas     |     -4.11813 |\n",
      "| mugabe     |     -4.10908 |\n",
      "| uks        |     -4.09073 |\n"
     ]
    }
   ],
   "source": [
    "# We do the same for the article titles\n",
    "\n",
    "X = data['title_standard']\n",
    "y = data['label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "\n",
    "y_pred_counts = nb_classifier.predict(X_test_counts)\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "log_probs_fake = nb_classifier.feature_log_prob_[0]\n",
    "log_probs_true = nb_classifier.feature_log_prob_[1]\n",
    "\n",
    "\n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'log_prob_fake': log_probs_fake,\n",
    "    'log_prob_true': log_probs_true\n",
    "})\n",
    "\n",
    "feature_df['fake_score'] = feature_df['log_prob_fake'] - feature_df['log_prob_true']\n",
    "top_fake_features = feature_df.sort_values(by='fake_score', ascending=False).head(20)\n",
    "top_true_features = feature_df.sort_values(by='fake_score', ascending=True).head(20)\n",
    "\n",
    "print(\"--- Naive Bayes Classification Results (Using Raw Word Counts) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_counts):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_counts))\n",
    "print(\"--- Top 20 Words Predicting FAKE News (Label 0) ---\")\n",
    "print(top_fake_features[['feature', 'fake_score']].to_markdown(index=False))\n",
    "print(\"\\n--- Top 20 Words Predicting TRUE News (Label 1) ---\")\n",
    "print(top_true_features[['feature', 'fake_score']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added cleaning step to handle noise observed from naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added cleaning step to handle noise in fake articles\n",
    "data['text_cleaned'] = data['text_standard']\n",
    "# Remove common URL patterns and link shorteners\n",
    "data['text_cleaned'] = data['text_cleaned'].str.replace(r'http[s]?://\\S+|www\\.\\S+|\\S+\\.(com|org|net|co|ly)|pictwittercom|httpstco|bitly', '', regex=True)\n",
    "# Remove photo/site credit words (getty, flickr, wikimedia, etc.)\n",
    "credit_patterns = r'getty|flickr|wikimedia|belowfeatured|somodevillagetty|mcnameegetty|angerergetty|wiretv|acr|cdata|filessupport'\n",
    "data['text_cleaned'] = data['text_cleaned'].str.replace(credit_patterns, '', regex=True)\n",
    "# Remove common code snippets and internal tags\n",
    "code_patterns = r'var|js|dgetelementsbytagnames|dcreateelements|dgetelementbyidid|jssrc|jsid|wfb|featured|screenshot|raedle|gage|donnell|whinedr|src|xfbml|parentnodeinsertbefore|versionv|screengrab|subscribing|nyp'\n",
    "data['text_cleaned'] = data['text_cleaned'].str.replace(code_patterns, ' ', regex=True)\n",
    "# Find all words that consist only of letters (a-z) and more than 2 characters long to get rid of fx 21Wire\n",
    "data['text_cleaned'] = data['text_cleaned'].str.findall(r'[a-z]{2,}')\n",
    "# Join the tokenized words into single string again\n",
    "data['text_cleaned'] = data['text_cleaned'].str.join(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run of bayes on newly cleaned article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes Classification Results (Using Raw Word Counts) ---\n",
      "Accuracy: 0.9418\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      3580\n",
      "           1       0.93      0.96      0.95      4237\n",
      "\n",
      "    accuracy                           0.94      7817\n",
      "   macro avg       0.94      0.94      0.94      7817\n",
      "weighted avg       0.94      0.94      0.94      7817\n",
      "\n",
      "--- Top 20 Words Predicting FAKE News (Label 0) ---\n",
      "| feature        |   fake_score |\n",
      "|:---------------|-------------:|\n",
      "| reilly         |      5.38192 |\n",
      "| finicum        |      5.36565 |\n",
      "| fcking         |      5.23757 |\n",
      "| henningsen     |      5.18661 |\n",
      "| whined         |      5.09064 |\n",
      "| bundy          |      5.05214 |\n",
      "| hammonds       |      4.81013 |\n",
      "| behar          |      4.81013 |\n",
      "| fck            |      4.7909  |\n",
      "| shit           |      4.7844  |\n",
      "| somodevilla    |      4.77129 |\n",
      "| watters        |      4.75129 |\n",
      "| elizabethforma |      4.74114 |\n",
      "| cher           |      4.72052 |\n",
      "| hilariously    |      4.71005 |\n",
      "| sarahpalinusa  |      4.69946 |\n",
      "| tantrum        |      4.69413 |\n",
      "| itthe          |      4.68877 |\n",
      "| hissy          |      4.68877 |\n",
      "| gitmo          |      4.67796 |\n",
      "\n",
      "--- Top 20 Words Predicting TRUE News (Label 1) ---\n",
      "| feature    |   fake_score |\n",
      "|:-----------|-------------:|\n",
      "| rohingya   |     -7.2566  |\n",
      "| myanmar    |     -6.45408 |\n",
      "| rakhine    |     -6.43824 |\n",
      "| puigdemont |     -6.07037 |\n",
      "| partys     |     -5.91457 |\n",
      "| zuma       |     -5.79707 |\n",
      "| suu        |     -5.76273 |\n",
      "| kyi        |     -5.75463 |\n",
      "| hariri     |     -5.66836 |\n",
      "| rajoy      |     -5.61215 |\n",
      "| mnangagwa  |     -5.55426 |\n",
      "| odinga     |     -5.54427 |\n",
      "| anc        |     -5.53081 |\n",
      "| catalan    |     -5.47385 |\n",
      "| tmsnrtrs   |     -5.47145 |\n",
      "| chinas     |     -5.41978 |\n",
      "| juncker    |     -5.40451 |\n",
      "| countrys   |     -5.30766 |\n",
      "| barnier    |     -5.30342 |\n",
      "| kuczynski  |     -5.28191 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Features (X) and Target (y)\n",
    "X = data['text_cleaned']  \n",
    "y = data['label']\n",
    "\n",
    "# Splitting the data and making sure we get the same number of labels in each set with stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Setting max_df to 0.7 we exclude words that appears in more than 70% of all articles in the training set so we should get more unique words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Train Multinomial Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# 5. Predict and Evaluate\n",
    "y_pred_counts = nb_classifier.predict(X_test_counts)\n",
    "\n",
    "# Get the feature names to see which words are helping us predict\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Getting log coefficients \n",
    "log_probs_fake = nb_classifier.feature_log_prob_[0]\n",
    "log_probs_true = nb_classifier.feature_log_prob_[1]\n",
    "\n",
    "# Create a DataFrame so we can sort them \n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'log_prob_fake': log_probs_fake,\n",
    "    'log_prob_true': log_probs_true\n",
    "})\n",
    "\n",
    "# Calculate the difference between coefficients \n",
    "# A larger positive difference means the word is highly associated with fake news\n",
    "feature_df['fake_score'] = feature_df['log_prob_fake'] - feature_df['log_prob_true']\n",
    "\n",
    "# 5. Get top 20 for Fake (highest positive scores)\n",
    "top_fake_features = feature_df.sort_values(by='fake_score', ascending=False).head(20)\n",
    "\n",
    "# 6. Get top 20 for True (lowest negative scores)\n",
    "top_true_features = feature_df.sort_values(by='fake_score', ascending=True).head(20)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"--- Naive Bayes Classification Results (Using Raw Word Counts) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_counts):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_counts))\n",
    "\n",
    "# Print important classifying words\n",
    "print(\"--- Top 20 Words Predicting FAKE News (Label 0) ---\")\n",
    "print(top_fake_features[['feature', 'fake_score']].to_markdown(index=False))\n",
    "\n",
    "print(\"\\n--- Top 20 Words Predicting TRUE News (Label 1) ---\")\n",
    "print(top_true_features[['feature', 'fake_score']].to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
